{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f0727e",
   "metadata": {},
   "source": [
    "# ResNet74构建  \n",
    "## 层数  \n",
    "74指的是74层可学习层数(主要指卷积层)   \n",
    "\n",
    "**resnet50层数**    \n",
    "初始层: 1个卷积层 (conv1)   \n",
    "├── Stage 2: 3个残差块 × 每个块3个卷积层 = 9个卷积层    \n",
    "├── Stage 3: 4个残差块 × 3个卷积层 = 12个卷积层  \n",
    "├── Stage 4: 6个残差块 × 3个卷积层 = 18个卷积层    \n",
    "├── Stage 5: 3个残差块 × 3个卷积层 = 9个卷积层   \n",
    "└── 分类头: 1个全连接层  \n",
    "总计50层  \n",
    "\n",
    "标准ResNet层数 = 初始层 + 各Stage残差块的总卷积层 + 分类层   \n",
    "\n",
    "## ResNet74设计  \n",
    "**resnet74层数**\n",
    "初始层: 1个卷积层 (conv1)     \n",
    "├── Stage 2: 3个残差块 × 每个块3个卷积层 = 9个卷积层       \n",
    "├── Stage 3: 6个残差块 × 3个卷积层 = 18个卷积层    \n",
    "├── Stage 4: 12个残差块 × 3个卷积层 = 36个卷积层     \n",
    "├── Stage 5: 3个残差块 × 3个卷积层 = 9个卷积层   \n",
    "└── 分类头: 1个全连接层\n",
    "总计：1 + 9 + 24 + 36 + 9 + 1 = 74层 (含1个FC层)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b3f56",
   "metadata": {},
   "source": [
    "## 关于resnet的bottleneck等残差块的用法 \n",
    "### 1.bottleneck  \n",
    "bottleneck是resnet的残差块，其工作流程为     \n",
    "```  \n",
    "输入 [256通道]   \n",
    "    ↓  \n",
    "1×1 Conv (降维) → [64通道]   \n",
    "    ↓      \n",
    "3×3 Conv (处理) → [64通道]  \n",
    "    ↓  \n",
    "1×1 Conv (升维) → [256通道]  \n",
    "    ↓  \n",
    "+ 输入 → 输出 [256通道]  \n",
    "```  \n",
    "使用残差块可以改变输入的维度，从而与网络的输出匹配，实现相加  \n",
    "\n",
    "**参数**   \n",
    "inplanes=3, 输入3通道  \n",
    "planes=64, 中间层通道数    \n",
    "expansion = 4, 扩展因子，压缩和放大比率，bottleneck内部定义好的    \n",
    "中间通道数压缩到64通道，极大减少计算量，最后再由64-> 4 * 64 升维，匹配维度   \n",
    "\n",
    "**解释**  \n",
    "一个残差块，本质上就是3个卷积层+残差传播  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5def99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "from torchvision.models.resnet import Bottleneck,BasicBlock\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from src import ResNet74, train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f416305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 加载数据 \n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data Preprocessing\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 导入库 ==========\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from src import ResNet74, train_model, test_model\n",
    "\n",
    "# ========== 超参数 ==========\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# ========== 数据加载 ==========\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ========== 模型定义 ==========\n",
    "# 定义ResNet74模型\n",
    "resnet74 = ResNet74()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet74.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型移动到GPU\n",
    "resnet74.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c13a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "print(\"开始训练...\")\n",
    "train_model(resnet74, trainloader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d63cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证：直接复用 test_model\n",
    "test_acc = test_model(resnet74, testloader, device)\n",
    "print(f\"[验证] test_acc: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae865a5c",
   "metadata": {},
   "source": [
    "尝试先进行下采样  \n",
    "\n",
    "在初始化层进行下采样，(32\\*32->8\\*8)  \n",
    "能够极大的提高速度，但是采样效果如何需要检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e202c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 导入库 ==========\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from src import ResNet74_ForwardDownsample, train_model, test_model\n",
    "\n",
    "# ========== 超参数 ==========\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# ========== 数据加载 ==========\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ========== 模型定义 ==========\n",
    "# 提前下采样\n",
    "resnet74_forward_downsample = ResNet74_ForwardDownsample()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet74_forward_downsample.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型移动到GPU\n",
    "resnet74_forward_downsample.to(device)\n",
    "\n",
    "# ========== 训练 ==========\n",
    "print(\"开始训练...\")\n",
    "train_model(resnet74_forward_downsample, trainloader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1997b",
   "metadata": {},
   "source": [
    "**分析** \n",
    "提前采样对于模型的效果几乎没有影响，但是速度提高了几倍，因此后续选择提前下采样模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21d578",
   "metadata": {},
   "source": [
    "## 与resnet50和resnet101对比  \n",
    "**resnet50**训练结果为：  \n",
    "```\n",
    "Epoch [1/10], Step [100/391], Loss: 0.7444\n",
    "Epoch [1/10], Step [200/391], Loss: 0.7427\n",
    "Epoch [1/10], Step [300/391], Loss: 0.7702\n",
    "Epoch [1/10] Finished. Loss: 0.9023, Acc: 69.60%, Time: 13.13s\n",
    "Epoch [2/10], Step [100/391], Loss: 0.4222\n",
    "Epoch [2/10], Step [200/391], Loss: 0.4974\n",
    "Epoch [2/10], Step [300/391], Loss: 0.5619\n",
    "Epoch [2/10] Finished. Loss: 0.5742, Acc: 80.86%, Time: 12.18s\n",
    "Epoch [3/10], Step [100/391], Loss: 0.4592\n",
    "Epoch [3/10], Step [200/391], Loss: 0.5474\n",
    "Epoch [3/10], Step [300/391], Loss: 0.8081\n",
    "Epoch [3/10] Finished. Loss: 0.4961, Acc: 83.45%, Time: 12.09s\n",
    "Epoch [4/10], Step [100/391], Loss: 0.3375\n",
    "Epoch [4/10], Step [200/391], Loss: 0.5660\n",
    "Epoch [4/10], Step [300/391], Loss: 0.4323\n",
    "Epoch [4/10] Finished. Loss: 0.4513, Acc: 84.94%, Time: 13.55s\n",
    "Epoch [5/10], Step [100/391], Loss: 0.4669\n",
    "Epoch [5/10], Step [200/391], Loss: 0.5576\n",
    "Epoch [5/10], Step [300/391], Loss: 0.3808\n",
    "Epoch [5/10] Finished. Loss: 0.4130, Acc: 86.02%, Time: 12.94s\n",
    "Epoch [6/10], Step [100/391], Loss: 0.3590\n",
    "Epoch [6/10], Step [200/391], Loss: 0.3644\n",
    "Epoch [6/10], Step [300/391], Loss: 0.3143\n",
    "Epoch [6/10] Finished. Loss: 0.3839, Acc: 87.01%, Time: 12.78s\n",
    "Epoch [7/10], Step [100/391], Loss: 0.4016\n",
    "Epoch [7/10], Step [200/391], Loss: 0.5128\n",
    "Epoch [7/10], Step [300/391], Loss: 0.3991\n",
    "Epoch [7/10] Finished. Loss: 0.3611, Acc: 87.91%, Time: 12.61s\n",
    "Epoch [8/10], Step [100/391], Loss: 0.3980\n",
    "Epoch [8/10], Step [200/391], Loss: 0.3987\n",
    "Epoch [8/10], Step [300/391], Loss: 0.3759\n",
    "Epoch [8/10] Finished. Loss: 0.3526, Acc: 88.08%, Time: 12.54s\n",
    "Epoch [9/10], Step [100/391], Loss: 0.3414\n",
    "Epoch [9/10], Step [200/391], Loss: 0.3202\n",
    "Epoch [9/10], Step [300/391], Loss: 0.3707\n",
    "Epoch [9/10] Finished. Loss: 0.3283, Acc: 88.86%, Time: 13.47s\n",
    "Epoch [10/10], Step [100/391], Loss: 0.2357\n",
    "Epoch [10/10], Step [200/391], Loss: 0.3436\n",
    "Epoch [10/10], Step [300/391], Loss: 0.3381\n",
    "Epoch [10/10] Finished. Loss: 0.3213, Acc: 89.10%, Time: 12.42s\n",
    "```\n",
    "其**混淆矩阵**为:  \n",
    "\n",
    "![](/home/frank/files/programs/AI引论第三次实验/docs/图/image.png)\n",
    "\n",
    "**resnet74**(提前下采样版)训练结果为  \n",
    "```\n",
    "开始训练...\n",
    "Epoch [1/10], Step [100/391], Loss: 1.8861\n",
    "Epoch [1/10], Step [200/391], Loss: 1.7756\n",
    "Epoch [1/10], Step [300/391], Loss: 1.4092\n",
    "Epoch [1/10] Finished. Loss: 1.8694, Acc: 32.17%, Time: 28.33s\n",
    "Epoch [2/10], Step [100/391], Loss: 1.4348\n",
    "Epoch [2/10], Step [200/391], Loss: 1.5027\n",
    "Epoch [2/10], Step [300/391], Loss: 1.5143\n",
    "Epoch [2/10] Finished. Loss: 1.4333, Acc: 47.85%, Time: 27.79s\n",
    "Epoch [3/10], Step [100/391], Loss: 1.1920\n",
    "Epoch [3/10], Step [200/391], Loss: 1.3776\n",
    "Epoch [3/10], Step [300/391], Loss: 1.0717\n",
    "Epoch [3/10] Finished. Loss: 1.2141, Acc: 56.63%, Time: 27.81s\n",
    "Epoch [4/10], Step [100/391], Loss: 1.1107\n",
    "Epoch [4/10], Step [200/391], Loss: 1.1451\n",
    "Epoch [4/10], Step [300/391], Loss: 1.6226\n",
    "Epoch [4/10] Finished. Loss: 1.1555, Acc: 58.94%, Time: 27.77s\n",
    "Epoch [5/10], Step [100/391], Loss: 0.9038\n",
    "Epoch [5/10], Step [200/391], Loss: 0.9857\n",
    "Epoch [5/10], Step [300/391], Loss: 0.8440\n",
    "Epoch [5/10] Finished. Loss: 0.9981, Acc: 64.54%, Time: 27.72s\n",
    "Epoch [6/10], Step [100/391], Loss: 0.9491\n",
    "Epoch [6/10], Step [200/391], Loss: 0.7109\n",
    "Epoch [6/10], Step [300/391], Loss: 0.9405\n",
    "Epoch [6/10] Finished. Loss: 0.8585, Acc: 70.00%, Time: 27.77s\n",
    "Epoch [7/10], Step [100/391], Loss: 0.8924\n",
    "Epoch [7/10], Step [200/391], Loss: 0.6162\n",
    "Epoch [7/10], Step [300/391], Loss: 0.6777\n",
    "Epoch [7/10] Finished. Loss: 0.7376, Acc: 74.24%, Time: 27.78s\n",
    "Epoch [8/10], Step [100/391], Loss: 0.6907\n",
    "Epoch [8/10], Step [200/391], Loss: 0.7328\n",
    "Epoch [8/10], Step [300/391], Loss: 0.4758\n",
    "Epoch [8/10] Finished. Loss: 0.6548, Acc: 77.32%, Time: 27.73s\n",
    "Epoch [9/10], Step [100/391], Loss: 0.7051\n",
    "Epoch [9/10], Step [200/391], Loss: 0.6360\n",
    "Epoch [9/10], Step [300/391], Loss: 0.6406\n",
    "Epoch [9/10] Finished. Loss: 0.6433, Acc: 77.88%, Time: 27.77s\n",
    "Epoch [10/10], Step [100/391], Loss: 0.5214\n",
    "Epoch [10/10], Step [200/391], Loss: 0.5709\n",
    "Epoch [10/10], Step [300/391], Loss: 0.6254\n",
    "Epoch [10/10] Finished. Loss: 0.5527, Acc: 81.01%, Time: 27.75s\n",
    "```\n",
    "其**混淆矩阵**为：  \n",
    "![](/home/frank/files/programs/AI引论第三次实验/docs/图/image2.png)\n",
    "\n",
    "**resnet101**训练结果为：  \n",
    "```\n",
    "Epoch [1/10], Step [100/391], Loss: 1.0764\n",
    "Epoch [1/10], Step [200/391], Loss: 0.8227\n",
    "Epoch [1/10], Step [300/391], Loss: 0.6122\n",
    "Epoch [1/10] Finished. Loss: 0.9219, Acc: 69.06%, Time: 46.20s\n",
    "Epoch [2/10], Step [100/391], Loss: 0.6602\n",
    "Epoch [2/10], Step [200/391], Loss: 0.5660\n",
    "Epoch [2/10], Step [300/391], Loss: 0.5085\n",
    "Epoch [2/10] Finished. Loss: 0.6540, Acc: 78.40%, Time: 45.42s\n",
    "Epoch [3/10], Step [100/391], Loss: 0.5468\n",
    "Epoch [3/10], Step [200/391], Loss: 0.5041\n",
    "Epoch [3/10], Step [300/391], Loss: 0.6935\n",
    "Epoch [3/10] Finished. Loss: 0.6301, Acc: 78.74%, Time: 45.17s\n",
    "Epoch [4/10], Step [100/391], Loss: 0.4524\n",
    "Epoch [4/10], Step [200/391], Loss: 0.4250\n",
    "Epoch [4/10], Step [300/391], Loss: 1.0053\n",
    "Epoch [4/10] Finished. Loss: 0.5687, Acc: 80.82%, Time: 45.43s\n",
    "Epoch [5/10], Step [100/391], Loss: 0.5762\n",
    "Epoch [5/10], Step [200/391], Loss: 0.6150\n",
    "Epoch [5/10], Step [300/391], Loss: 0.6673\n",
    "Epoch [5/10] Finished. Loss: 0.5793, Acc: 80.46%, Time: 45.33s\n",
    "Epoch [6/10], Step [100/391], Loss: 0.3270\n",
    "Epoch [6/10], Step [200/391], Loss: 0.7554\n",
    "Epoch [6/10], Step [300/391], Loss: 0.5401\n",
    "Epoch [6/10] Finished. Loss: 0.4772, Acc: 83.72%, Time: 45.63s\n",
    "Epoch [7/10], Step [100/391], Loss: 0.4165\n",
    "Epoch [7/10], Step [200/391], Loss: 0.4409\n",
    "Epoch [7/10], Step [300/391], Loss: 0.4321\n",
    "Epoch [7/10] Finished. Loss: 0.4149, Acc: 85.88%, Time: 45.57s\n",
    "Epoch [8/10], Step [100/391], Loss: 0.4250\n",
    "Epoch [8/10], Step [200/391], Loss: 0.3236\n",
    "Epoch [8/10], Step [300/391], Loss: 0.4051\n",
    "Epoch [8/10] Finished. Loss: 0.3883, Acc: 86.64%, Time: 45.76s\n",
    "Epoch [9/10], Step [100/391], Loss: 0.4278\n",
    "Epoch [9/10], Step [200/391], Loss: 0.4560\n",
    "Epoch [9/10], Step [300/391], Loss: 0.3332\n",
    "Epoch [9/10] Finished. Loss: 0.3874, Acc: 86.89%, Time: 45.49s\n",
    "Epoch [10/10], Step [100/391], Loss: 0.2510\n",
    "Epoch [10/10], Step [200/391], Loss: 0.3466\n",
    "Epoch [10/10], Step [300/391], Loss: 0.6309\n",
    "Epoch [10/10] Finished. Loss: 0.3696, Acc: 87.40%, Time: 45.01s\n",
    "```\n",
    "其**混淆矩阵**为：  \n",
    "![](/home/frank/files/programs/AI引论第三次实验/docs/图/image3.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a210974c",
   "metadata": {},
   "source": [
    "训练时间为resnet50 = resnet74/2 = resnet101/4    \n",
    "而准确度方面略有提升，但是不多，可能是因为数据模型较简单  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5decd12c",
   "metadata": {},
   "source": [
    "## 不同epcho训练  \n",
    "epcho_less = 5  \n",
    "epcho_more = 15  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== 导入库 ==========\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from src import ResNet74_ForwardDownsample, train_model, test_model, plot_confusion_matrix\n",
    "\n",
    "# ========== 超参数 ==========\n",
    "epcho_less = 5\n",
    "epcho_more = 15\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# ========== 数据加载 ==========\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ========== 模型定义 ==========\n",
    "# 提前下采样模型\n",
    "resnet74_forward_downsample_less_epcho = ResNet74_ForwardDownsample()\n",
    "resnet74_forward_downsample_more_epcho = ResNet74_ForwardDownsample()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_for_less = optim.Adam(resnet74_forward_downsample_less_epcho.parameters(), lr=learning_rate)\n",
    "optimizer_for_more = optim.Adam(resnet74_forward_downsample_more_epcho.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型移动到GPU\n",
    "resnet74_forward_downsample_less_epcho.to(device)\n",
    "resnet74_forward_downsample_more_epcho.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652fc0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "print(\"开始训练少epcho模型...\")\n",
    "train_model(resnet74_forward_downsample_less_epcho, trainloader, criterion, optimizer_for_less, epcho_less, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"开始训练多epcho模型...\")\n",
    "train_model(resnet74_forward_downsample_more_epcho, trainloader, criterion, optimizer_for_more, epcho_more, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f21a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "test_acc_less_epcho = test_model(resnet74_forward_downsample_less_epcho, testloader, device)\n",
    "test_acc_more_epcho = test_model(resnet74_forward_downsample_more_epcho, testloader, device)\n",
    "\n",
    "print(f\"epcho_less: {test_acc_less_epcho}, epcho_more: {test_acc_more_epcho}\")\n",
    "\n",
    "# 混淆矩阵\n",
    "plot_confusion_matrix(resnet74_forward_downsample_less_epcho, testloader, device)\n",
    "plot_confusion_matrix(resnet74_forward_downsample_more_epcho, testloader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727fd175",
   "metadata": {},
   "source": [
    "**训练结果**  \n",
    "```\n",
    "少epcho模型...\n",
    "Epoch [1/5], Step [100/391], Loss: 1.8486\n",
    "Epoch [1/5], Step [200/391], Loss: 1.6182\n",
    "Epoch [1/5], Step [300/391], Loss: 1.5407\n",
    "Epoch [1/5] Finished. Loss: 1.7783, Acc: 35.41%, Time: 28.03s\n",
    "Epoch [2/5], Step [100/391], Loss: 1.4870\n",
    "Epoch [2/5], Step [200/391], Loss: 1.3618\n",
    "Epoch [2/5], Step [300/391], Loss: 1.2692\n",
    "Epoch [2/5] Finished. Loss: 1.3505, Acc: 51.24%, Time: 27.85s\n",
    "Epoch [3/5], Step [100/391], Loss: 1.2715\n",
    "Epoch [3/5], Step [200/391], Loss: 1.1449\n",
    "Epoch [3/5], Step [300/391], Loss: 1.1403\n",
    "Epoch [3/5] Finished. Loss: 1.2610, Acc: 55.08%, Time: 27.84s\n",
    "Epoch [4/5], Step [100/391], Loss: 1.0273\n",
    "Epoch [4/5], Step [200/391], Loss: 1.0395\n",
    "Epoch [4/5], Step [300/391], Loss: 1.0795\n",
    "Epoch [4/5] Finished. Loss: 1.0639, Acc: 62.20%, Time: 27.83s\n",
    "Epoch [5/5], Step [100/391], Loss: 0.8022\n",
    "Epoch [5/5], Step [200/391], Loss: 0.8870\n",
    "Epoch [5/5], Step [300/391], Loss: 1.0477\n",
    "Epoch [5/5] Finished. Loss: 0.8941, Acc: 68.48%, Time: 27.86s\n",
    "```\n",
    "混淆矩阵和准确率见代码块\n",
    "\n",
    "\n",
    "```\n",
    "开始训练多epcho模型...\n",
    "Epoch [1/15], Step [100/391], Loss: 1.8893\n",
    "Epoch [1/15], Step [200/391], Loss: 1.9474\n",
    "Epoch [1/15], Step [300/391], Loss: 1.5950\n",
    "Epoch [1/15] Finished. Loss: 1.7850, Acc: 35.43%, Time: 28.23s\n",
    "Epoch [2/15], Step [100/391], Loss: 1.2189\n",
    "Epoch [2/15], Step [200/391], Loss: 1.3935\n",
    "Epoch [2/15], Step [300/391], Loss: 1.6186\n",
    "Epoch [2/15] Finished. Loss: 1.3937, Acc: 49.60%, Time: 27.93s\n",
    "Epoch [3/15], Step [100/391], Loss: 1.3161\n",
    "Epoch [3/15], Step [200/391], Loss: 1.1906\n",
    "Epoch [3/15], Step [300/391], Loss: 1.3275\n",
    "Epoch [3/15] Finished. Loss: 1.2331, Acc: 55.88%, Time: 27.89s\n",
    "Epoch [4/15], Step [100/391], Loss: 1.0584\n",
    "Epoch [4/15], Step [200/391], Loss: 1.0186\n",
    "Epoch [4/15], Step [300/391], Loss: 0.8985\n",
    "Epoch [4/15] Finished. Loss: 1.0345, Acc: 63.41%, Time: 28.01s\n",
    "Epoch [5/15], Step [100/391], Loss: 0.8054\n",
    "Epoch [5/15], Step [200/391], Loss: 0.9698\n",
    "Epoch [5/15], Step [300/391], Loss: 0.7892\n",
    "Epoch [5/15] Finished. Loss: 0.8872, Acc: 68.75%, Time: 27.96s\n",
    "Epoch [6/15], Step [100/391], Loss: 0.7485\n",
    "Epoch [6/15], Step [200/391], Loss: 0.8768\n",
    "Epoch [6/15], Step [300/391], Loss: 0.6838\n",
    "Epoch [6/15] Finished. Loss: 0.7760, Acc: 72.82%, Time: 27.91s\n",
    "Epoch [7/15], Step [100/391], Loss: 0.6107\n",
    "Epoch [7/15], Step [200/391], Loss: 0.7260\n",
    "Epoch [7/15], Step [300/391], Loss: 0.6078\n",
    "Epoch [7/15] Finished. Loss: 0.7016, Acc: 75.50%, Time: 27.91s\n",
    "Epoch [8/15], Step [100/391], Loss: 0.6772\n",
    "Epoch [8/15], Step [200/391], Loss: 0.6345\n",
    "Epoch [8/15], Step [300/391], Loss: 0.6877\n",
    "Epoch [8/15] Finished. Loss: 0.6305, Acc: 78.07%, Time: 28.01s\n",
    "Epoch [9/15], Step [100/391], Loss: 0.7210\n",
    "Epoch [9/15], Step [200/391], Loss: 0.6852\n",
    "Epoch [9/15], Step [300/391], Loss: 0.5579\n",
    "Epoch [9/15] Finished. Loss: 0.5839, Acc: 79.90%, Time: 27.89s\n",
    "Epoch [10/15], Step [100/391], Loss: 0.5321\n",
    "Epoch [10/15], Step [200/391], Loss: 0.4527\n",
    "Epoch [10/15], Step [300/391], Loss: 0.5371\n",
    "Epoch [10/15] Finished. Loss: 0.5415, Acc: 81.23%, Time: 27.86s\n",
    "Epoch [11/15], Step [100/391], Loss: 0.5609\n",
    "Epoch [11/15], Step [200/391], Loss: 0.5817\n",
    "Epoch [11/15], Step [300/391], Loss: 0.5312\n",
    "Epoch [11/15] Finished. Loss: 0.5040, Acc: 82.57%, Time: 27.89s\n",
    "Epoch [12/15], Step [100/391], Loss: 0.5155\n",
    "Epoch [12/15], Step [200/391], Loss: 0.4372\n",
    "Epoch [12/15], Step [300/391], Loss: 0.5019\n",
    "Epoch [12/15] Finished. Loss: 0.4767, Acc: 83.40%, Time: 27.84s\n",
    "Epoch [13/15], Step [100/391], Loss: 0.4135\n",
    "Epoch [13/15], Step [200/391], Loss: 0.4565\n",
    "Epoch [13/15], Step [300/391], Loss: 0.4121\n",
    "Epoch [13/15] Finished. Loss: 0.4538, Acc: 84.32%, Time: 27.83s\n",
    "Epoch [14/15], Step [100/391], Loss: 0.3785\n",
    "Epoch [14/15], Step [200/391], Loss: 0.5740\n",
    "Epoch [14/15], Step [300/391], Loss: 0.4304\n",
    "Epoch [14/15] Finished. Loss: 0.4272, Acc: 85.45%, Time: 27.77s\n",
    "Epoch [15/15], Step [100/391], Loss: 0.3762\n",
    "Epoch [15/15], Step [200/391], Loss: 0.3297\n",
    "Epoch [15/15], Step [300/391], Loss: 0.5063\n",
    "Epoch [15/15] Finished. Loss: 0.4003, Acc: 86.16%, Time: 27.85s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64617764",
   "metadata": {},
   "source": [
    "## 训练增强\n",
    "基于自主设计ResNet74模型，设计实现至少包括亮度调整、随机噪声、色调调整、随机裁剪、随机翻转、Mixup的数据增强策略；并探讨分析不同数据增强策略对模型性能的影响；  \n",
    "\n",
    "**实现方式**   \n",
    "使用transform.Compose实现  \n",
    "Compose中输入的是增强方式，统一对数据进行调用  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5efbcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import random\n",
    "random.seed(42) # 设置随机种子\n",
    "\n",
    "# 1.亮度+色调调整\n",
    "# 使用torchvision实现，本质上是对通道进行放缩\n",
    "brightness_aug = transforms.ColorJitter(brightness=0.2)\n",
    "\n",
    "# 2.随机噪声\n",
    "# 使用高斯噪声，本质上是给每个通道的每个像素加上一个(0,sigma^2)高斯分布的噪声\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, sigma=0.03, p=0.5):\n",
    "        self.sigma = sigma\n",
    "        self.p = p\n",
    "    def __call__(self, x):\n",
    "        if torch.rand(1).item() > self.p:\n",
    "            return x\n",
    "        return torch.clamp(x + torch.randn_like(x) * self.sigma, 0.0, 1.0)\n",
    "\n",
    "# 随机裁剪\n",
    "random_crop = transforms.RandomCrop(32, padding=4)\n",
    "\n",
    "# 随机水平翻转         \n",
    "random_horizontal_flip = transforms.RandomHorizontalFlip(p=0.5)             \n",
    "\n",
    "# 标准化\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))  # CIFAR-10数据的mean和std\n",
    "\n",
    "compser = transforms.Compose([\n",
    "    brightness_aug,\n",
    "    random_crop,\n",
    "    random_horizontal_flip,\n",
    "    transforms.ToTensor(),   # 转换为tensor后，才能增加噪声\n",
    "    AddGaussianNoise(sigma=0.03, p=0.5),\n",
    "    transforms.Normalize(*stats), # 标准化 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f951e915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 增强训练集\n",
    "# 加载数据 \n",
    "# Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data Preprocessing\n",
    "# CIFAR-10 stats for normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "Epoch [1/10], Step [100/391], Loss: 1.9633\n",
      "Epoch [1/10], Step [200/391], Loss: 1.5802\n",
      "Epoch [1/10], Step [300/391], Loss: 1.6270\n",
      "Epoch [1/10] Finished. Loss: 1.8107, Acc: 34.92%, Time: 32.75s\n",
      "Epoch [2/10], Step [100/391], Loss: 1.3612\n",
      "Epoch [2/10], Step [200/391], Loss: 1.7011\n",
      "Epoch [2/10], Step [300/391], Loss: 1.3324\n",
      "Epoch [2/10] Finished. Loss: 1.3707, Acc: 50.09%, Time: 32.11s\n",
      "Epoch [3/10], Step [100/391], Loss: 1.2249\n",
      "Epoch [3/10], Step [200/391], Loss: 1.0129\n",
      "Epoch [3/10], Step [300/391], Loss: 1.1321\n",
      "Epoch [3/10] Finished. Loss: 1.1463, Acc: 59.01%, Time: 32.23s\n",
      "Epoch [4/10], Step [100/391], Loss: 1.0608\n",
      "Epoch [4/10], Step [200/391], Loss: 0.8602\n",
      "Epoch [4/10], Step [300/391], Loss: 0.9724\n",
      "Epoch [4/10] Finished. Loss: 1.0054, Acc: 64.54%, Time: 32.23s\n",
      "Epoch [5/10], Step [100/391], Loss: 0.8051\n",
      "Epoch [5/10], Step [200/391], Loss: 1.0412\n",
      "Epoch [5/10], Step [300/391], Loss: 0.7768\n",
      "Epoch [5/10] Finished. Loss: 0.8828, Acc: 68.89%, Time: 32.20s\n",
      "Epoch [6/10], Step [100/391], Loss: 0.6868\n",
      "Epoch [6/10], Step [200/391], Loss: 0.9745\n",
      "Epoch [6/10], Step [300/391], Loss: 0.7198\n",
      "Epoch [6/10] Finished. Loss: 0.7762, Acc: 72.97%, Time: 32.22s\n",
      "Epoch [7/10], Step [100/391], Loss: 0.6809\n",
      "Epoch [7/10], Step [200/391], Loss: 0.6886\n",
      "Epoch [7/10], Step [300/391], Loss: 0.7381\n",
      "Epoch [7/10] Finished. Loss: 0.6759, Acc: 76.46%, Time: 32.36s\n",
      "Epoch [8/10], Step [100/391], Loss: 0.6103\n",
      "Epoch [8/10], Step [200/391], Loss: 0.5391\n",
      "Epoch [8/10], Step [300/391], Loss: 0.6168\n",
      "Epoch [8/10] Finished. Loss: 0.6306, Acc: 78.25%, Time: 32.45s\n",
      "Epoch [9/10], Step [100/391], Loss: 0.4286\n",
      "Epoch [9/10], Step [200/391], Loss: 0.4977\n",
      "Epoch [9/10], Step [300/391], Loss: 0.4577\n",
      "Epoch [9/10] Finished. Loss: 0.5728, Acc: 80.29%, Time: 32.23s\n",
      "Epoch [10/10], Step [100/391], Loss: 0.4904\n",
      "Epoch [10/10], Step [200/391], Loss: 0.5301\n",
      "Epoch [10/10], Step [300/391], Loss: 0.4686\n",
      "Epoch [10/10] Finished. Loss: 0.5291, Acc: 81.62%, Time: 31.99s\n"
     ]
    }
   ],
   "source": [
    "# ========== 导入库 ==========\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from src import ResNet74_ForwardDownsample, train_model, test_model\n",
    "\n",
    "# ========== 超参数 ==========\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "# ========== 数据加载 ==========\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ========== 模型定义 ==========\n",
    "# 提前下采样\n",
    "resnet74_forward_downsample = ResNet74_ForwardDownsample()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet74_forward_downsample.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型移动到GPU\n",
    "resnet74_forward_downsample.to(device)\n",
    "\n",
    "# ========== 训练 ==========\n",
    "print(\"开始训练...\")\n",
    "train_model(resnet74_forward_downsample, trainloader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f79b7",
   "metadata": {},
   "source": [
    "**训练结果**   \n",
    "```  \n",
    "Epoch [1/10], Step [100/391], Loss: 1.9633\n",
    "Epoch [1/10], Step [200/391], Loss: 1.5802\n",
    "Epoch [1/10], Step [300/391], Loss: 1.6270\n",
    "Epoch [1/10] Finished. Loss: 1.8107, Acc: 34.92%, Time: 32.75s\n",
    "Epoch [2/10], Step [100/391], Loss: 1.3612\n",
    "Epoch [2/10], Step [200/391], Loss: 1.7011\n",
    "Epoch [2/10], Step [300/391], Loss: 1.3324\n",
    "Epoch [2/10] Finished. Loss: 1.3707, Acc: 50.09%, Time: 32.11s\n",
    "Epoch [3/10], Step [100/391], Loss: 1.2249\n",
    "Epoch [3/10], Step [200/391], Loss: 1.0129\n",
    "Epoch [3/10], Step [300/391], Loss: 1.1321\n",
    "Epoch [3/10] Finished. Loss: 1.1463, Acc: 59.01%, Time: 32.23s\n",
    "Epoch [4/10], Step [100/391], Loss: 1.0608\n",
    "Epoch [4/10], Step [200/391], Loss: 0.8602\n",
    "Epoch [4/10], Step [300/391], Loss: 0.9724\n",
    "Epoch [4/10] Finished. Loss: 1.0054, Acc: 64.54%, Time: 32.23s\n",
    "Epoch [5/10], Step [100/391], Loss: 0.8051\n",
    "Epoch [5/10], Step [200/391], Loss: 1.0412\n",
    "Epoch [5/10], Step [300/391], Loss: 0.7768\n",
    "Epoch [5/10] Finished. Loss: 0.8828, Acc: 68.89%, Time: 32.20s\n",
    "Epoch [6/10], Step [100/391], Loss: 0.6868\n",
    "Epoch [6/10], Step [200/391], Loss: 0.9745\n",
    "Epoch [6/10], Step [300/391], Loss: 0.7198\n",
    "Epoch [6/10] Finished. Loss: 0.7762, Acc: 72.97%, Time: 32.22s\n",
    "Epoch [7/10], Step [100/391], Loss: 0.6809\n",
    "Epoch [7/10], Step [200/391], Loss: 0.6886\n",
    "Epoch [7/10], Step [300/391], Loss: 0.7381\n",
    "Epoch [7/10] Finished. Loss: 0.6759, Acc: 76.46%, Time: 32.36s\n",
    "Epoch [8/10], Step [100/391], Loss: 0.6103\n",
    "Epoch [8/10], Step [200/391], Loss: 0.5391\n",
    "Epoch [8/10], Step [300/391], Loss: 0.6168\n",
    "Epoch [8/10] Finished. Loss: 0.6306, Acc: 78.25%, Time: 32.45s\n",
    "Epoch [9/10], Step [100/391], Loss: 0.4286\n",
    "Epoch [9/10], Step [200/391], Loss: 0.4977\n",
    "Epoch [9/10], Step [300/391], Loss: 0.4577\n",
    "Epoch [9/10] Finished. Loss: 0.5728, Acc: 80.29%, Time: 32.23s\n",
    "Epoch [10/10], Step [100/391], Loss: 0.4904\n",
    "Epoch [10/10], Step [200/391], Loss: 0.5301\n",
    "Epoch [10/10], Step [300/391], Loss: 0.4686\n",
    "Epoch [10/10] Finished. Loss: 0.5291, Acc: 81.62%, Time: 31.99s\n",
    "```\n",
    "效果提升不明显  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429d3ee",
   "metadata": {},
   "source": [
    "## Dropout  \n",
    "dropout类似随机森林随机选择不同的特征和不同的样本进行分析，神经网络每次随机选择(1-dropout_rate)的神经元进行训练，这样能提高模型的稳健性，避免过拟合。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a3aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "开始训练带Dropout的模型...\n",
      "Epoch [1/10], Step [100/391], Loss: 1.8588\n",
      "Epoch [1/10], Step [200/391], Loss: 1.7270\n",
      "Epoch [1/10], Step [300/391], Loss: 1.6182\n",
      "Epoch [1/10] Finished. Loss: 1.8127, Acc: 34.88%, Time: 32.34s\n",
      "Epoch [2/10], Step [100/391], Loss: 1.5624\n",
      "Epoch [2/10], Step [200/391], Loss: 1.4140\n",
      "Epoch [2/10], Step [300/391], Loss: 1.3970\n",
      "Epoch [2/10] Finished. Loss: 1.3831, Acc: 50.09%, Time: 32.32s\n",
      "Epoch [3/10], Step [100/391], Loss: 1.3465\n",
      "Epoch [3/10], Step [200/391], Loss: 1.5738\n",
      "Epoch [3/10], Step [300/391], Loss: 1.1816\n",
      "Epoch [3/10] Finished. Loss: 1.2325, Acc: 56.84%, Time: 32.26s\n",
      "Epoch [4/10], Step [100/391], Loss: 1.1451\n",
      "Epoch [4/10], Step [200/391], Loss: 1.3160\n",
      "Epoch [4/10], Step [300/391], Loss: 1.1260\n",
      "Epoch [4/10] Finished. Loss: 1.0210, Acc: 64.39%, Time: 32.25s\n",
      "Epoch [5/10], Step [100/391], Loss: 0.9873\n",
      "Epoch [5/10], Step [200/391], Loss: 0.9453\n",
      "Epoch [5/10], Step [300/391], Loss: 0.7612\n",
      "Epoch [5/10] Finished. Loss: 0.9112, Acc: 68.32%, Time: 32.25s\n",
      "Epoch [6/10], Step [100/391], Loss: 0.7443\n",
      "Epoch [6/10], Step [200/391], Loss: 0.6399\n",
      "Epoch [6/10], Step [300/391], Loss: 0.8097\n",
      "Epoch [6/10] Finished. Loss: 0.7998, Acc: 72.35%, Time: 32.40s\n",
      "Epoch [7/10], Step [100/391], Loss: 0.6835\n",
      "Epoch [7/10], Step [200/391], Loss: 1.2223\n",
      "Epoch [7/10], Step [300/391], Loss: 0.7935\n",
      "Epoch [7/10] Finished. Loss: 0.9083, Acc: 68.67%, Time: 32.27s\n",
      "Epoch [8/10], Step [100/391], Loss: 0.6770\n",
      "Epoch [8/10], Step [200/391], Loss: 0.7064\n",
      "Epoch [8/10], Step [300/391], Loss: 1.0260\n",
      "Epoch [8/10] Finished. Loss: 0.8671, Acc: 70.15%, Time: 32.17s\n",
      "Epoch [9/10], Step [100/391], Loss: 0.6703\n",
      "Epoch [9/10], Step [200/391], Loss: 0.5689\n",
      "Epoch [9/10], Step [300/391], Loss: 0.6375\n",
      "Epoch [9/10] Finished. Loss: 0.6775, Acc: 76.51%, Time: 32.19s\n",
      "Epoch [10/10], Step [100/391], Loss: 0.5023\n",
      "Epoch [10/10], Step [200/391], Loss: 0.6268\n",
      "Epoch [10/10], Step [300/391], Loss: 0.6697\n",
      "Epoch [10/10] Finished. Loss: 0.5798, Acc: 79.91%, Time: 32.18s\n"
     ]
    }
   ],
   "source": [
    "# ========== 导入库 ==========\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from src import ResNet74_ForwardDownsample, train_model, test_model\n",
    "\n",
    "# ========== 超参数 ==========\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1  # Dropout比率，用于训练时防止过拟合\n",
    "\n",
    "# ========== 数据加载 ==========\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ========== 模型定义 ==========\n",
    "# 创建带Dropout的模型（dropout_rate=0.5，可在训练时防止过拟合）\n",
    "resnet74_forward_downsample_dropout = ResNet74_ForwardDownsample(dropout_rate=dropout_rate)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet74_forward_downsample_dropout.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型移动到GPU\n",
    "resnet74_forward_downsample_dropout.to(device)\n",
    "\n",
    "# ========== 训练 ==========\n",
    "# 训练（Dropout在训练模式下自动启用，在评估模式下自动关闭）\n",
    "print(\"开始训练带Dropout的模型...\")\n",
    "train_model(resnet74_forward_downsample_dropout, trainloader, criterion, optimizer, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d371c",
   "metadata": {},
   "source": [
    "**训练结果** \n",
    "尝试dropout_rate = 0.1 \n",
    "```\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "开始训练带Dropout的模型...\n",
    "Epoch [1/10], Step [100/391], Loss: 1.8588\n",
    "Epoch [1/10], Step [200/391], Loss: 1.7270\n",
    "Epoch [1/10], Step [300/391], Loss: 1.6182\n",
    "Epoch [1/10] Finished. Loss: 1.8127, Acc: 34.88%, Time: 32.34s\n",
    "Epoch [2/10], Step [100/391], Loss: 1.5624\n",
    "Epoch [2/10], Step [200/391], Loss: 1.4140\n",
    "Epoch [2/10], Step [300/391], Loss: 1.3970\n",
    "Epoch [2/10] Finished. Loss: 1.3831, Acc: 50.09%, Time: 32.32s\n",
    "Epoch [3/10], Step [100/391], Loss: 1.3465\n",
    "Epoch [3/10], Step [200/391], Loss: 1.5738\n",
    "Epoch [3/10], Step [300/391], Loss: 1.1816\n",
    "Epoch [3/10] Finished. Loss: 1.2325, Acc: 56.84%, Time: 32.26s\n",
    "Epoch [4/10], Step [100/391], Loss: 1.1451\n",
    "Epoch [4/10], Step [200/391], Loss: 1.3160\n",
    "Epoch [4/10], Step [300/391], Loss: 1.1260\n",
    "Epoch [4/10] Finished. Loss: 1.0210, Acc: 64.39%, Time: 32.25s\n",
    "Epoch [5/10], Step [100/391], Loss: 0.9873\n",
    "Epoch [5/10], Step [200/391], Loss: 0.9453\n",
    "Epoch [5/10], Step [300/391], Loss: 0.7612\n",
    "Epoch [5/10] Finished. Loss: 0.9112, Acc: 68.32%, Time: 32.25s\n",
    "Epoch [6/10], Step [100/391], Loss: 0.7443\n",
    "Epoch [6/10], Step [200/391], Loss: 0.6399\n",
    "Epoch [6/10], Step [300/391], Loss: 0.8097\n",
    "Epoch [6/10] Finished. Loss: 0.7998, Acc: 72.35%, Time: 32.40s\n",
    "Epoch [7/10], Step [100/391], Loss: 0.6835\n",
    "Epoch [7/10], Step [200/391], Loss: 1.2223\n",
    "Epoch [7/10], Step [300/391], Loss: 0.7935\n",
    "Epoch [7/10] Finished. Loss: 0.9083, Acc: 68.67%, Time: 32.27s\n",
    "Epoch [8/10], Step [100/391], Loss: 0.6770\n",
    "Epoch [8/10], Step [200/391], Loss: 0.7064\n",
    "Epoch [8/10], Step [300/391], Loss: 1.0260\n",
    "Epoch [8/10] Finished. Loss: 0.8671, Acc: 70.15%, Time: 32.17s\n",
    "Epoch [9/10], Step [100/391], Loss: 0.6703\n",
    "Epoch [9/10], Step [200/391], Loss: 0.5689\n",
    "Epoch [9/10], Step [300/391], Loss: 0.6375\n",
    "Epoch [9/10] Finished. Loss: 0.6775, Acc: 76.51%, Time: 32.19s\n",
    "Epoch [10/10], Step [100/391], Loss: 0.5023\n",
    "Epoch [10/10], Step [200/391], Loss: 0.6268\n",
    "Epoch [10/10], Step [300/391], Loss: 0.6697\n",
    "Epoch [10/10] Finished. Loss: 0.5798, Acc: 79.91%, Time: 32.18s\n",
    "```\n",
    "\n",
    "尝试dropout_rate = 0.5   \n",
    "```\n",
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "开始训练带Dropout的模型...\n",
    "Epoch [1/10], Step [100/391], Loss: 2.5184\n",
    "Epoch [1/10], Step [200/391], Loss: 1.9133\n",
    "Epoch [1/10], Step [300/391], Loss: 1.9602\n",
    "Epoch [1/10] Finished. Loss: 1.9317, Acc: 31.98%, Time: 32.65s\n",
    "Epoch [2/10], Step [100/391], Loss: 1.6535\n",
    "Epoch [2/10], Step [200/391], Loss: 1.6508\n",
    "Epoch [2/10], Step [300/391], Loss: 1.4679\n",
    "Epoch [2/10] Finished. Loss: 1.5205, Acc: 46.19%, Time: 32.28s\n",
    "Epoch [3/10], Step [100/391], Loss: 1.4125\n",
    "Epoch [3/10], Step [200/391], Loss: 1.3044\n",
    "Epoch [3/10], Step [300/391], Loss: 1.4053\n",
    "Epoch [3/10] Finished. Loss: 1.4422, Acc: 49.20%, Time: 32.38s\n",
    "Epoch [4/10], Step [100/391], Loss: 1.5226\n",
    "Epoch [4/10], Step [200/391], Loss: 1.2685\n",
    "Epoch [4/10], Step [300/391], Loss: 1.3416\n",
    "Epoch [4/10] Finished. Loss: 1.2904, Acc: 55.24%, Time: 32.26s\n",
    "Epoch [5/10], Step [100/391], Loss: 1.0342\n",
    "Epoch [5/10], Step [200/391], Loss: 1.1651\n",
    "Epoch [5/10], Step [300/391], Loss: 0.9670\n",
    "Epoch [5/10] Finished. Loss: 1.1500, Acc: 60.68%, Time: 32.34s\n",
    "Epoch [6/10], Step [100/391], Loss: 1.3182\n",
    "Epoch [6/10], Step [200/391], Loss: 1.0687\n",
    "Epoch [6/10], Step [300/391], Loss: 1.0229\n",
    "Epoch [6/10] Finished. Loss: 1.0907, Acc: 63.30%, Time: 32.23s\n",
    "Epoch [7/10], Step [100/391], Loss: 1.5879\n",
    "Epoch [7/10], Step [200/391], Loss: 1.1042\n",
    "Epoch [7/10], Step [300/391], Loss: 1.5659\n",
    "Epoch [7/10] Finished. Loss: 1.2071, Acc: 58.54%, Time: 32.26s\n",
    "Epoch [8/10], Step [100/391], Loss: 1.1420\n",
    "Epoch [8/10], Step [200/391], Loss: 1.3771\n",
    "Epoch [8/10], Step [300/391], Loss: 1.3157\n",
    "Epoch [8/10] Finished. Loss: 1.0996, Acc: 62.67%, Time: 32.23s\n",
    "Epoch [9/10], Step [100/391], Loss: 0.8296\n",
    "Epoch [9/10], Step [200/391], Loss: 0.7793\n",
    "Epoch [9/10], Step [300/391], Loss: 0.7730\n",
    "Epoch [9/10] Finished. Loss: 0.9814, Acc: 66.32%, Time: 32.18s\n",
    "Epoch [10/10], Step [100/391], Loss: 1.0850\n",
    "Epoch [10/10], Step [200/391], Loss: 0.8481\n",
    "Epoch [10/10], Step [300/391], Loss: 0.8189\n",
    "Epoch [10/10] Finished. Loss: 0.8438, Acc: 70.88%, Time: 32.12s\n",
    "```\n",
    "\n",
    "发现使用dropout效果不好，可能需要尝试更低的dropout_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f913b07",
   "metadata": {},
   "source": [
    "## 不同学习器、学习率、学习策略\n",
    "**三种优化器配置**  \n",
    "- SGD + StepLR（阶梯式衰减）  \n",
    "    - 学习率：0.01（SGD 通常需要更大）  \n",
    "    - 动量：0.9  \n",
    "    - 调度策略：每 3 个 epoch 学习率乘以 0.1    \n",
    "\n",
    "- Adam + CosineAnnealingLR（余弦退火）  \n",
    "    - 学习率：0.001  \n",
    "    - 调度策略：余弦退火，学习率按余弦函数衰减\n",
    "\n",
    "- RMSprop + ExponentialLR（指数衰减）    \n",
    "    - 学习率：0.001  \n",
    "    - 调度策略：每个 epoch 学习率乘以 0.95  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838e2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "============================================================\n",
      "训练 SGD + StepLR 模型\n",
      "============================================================\n",
      "[SGD+StepLR] Epoch [1/10], Step [100/391], Loss: 2.2414, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [1/10], Step [200/391], Loss: 2.2793, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [1/10], Step [300/391], Loss: 2.1041, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [1/10] Finished. Loss: 2.1984, Acc: 24.92%, LR: 0.010000\n",
      "\n",
      "[SGD+StepLR] Epoch [2/10], Step [100/391], Loss: 1.5160, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [2/10], Step [200/391], Loss: 1.6396, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [2/10], Step [300/391], Loss: 1.8833, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [2/10] Finished. Loss: 1.6414, Acc: 39.70%, LR: 0.010000\n",
      "\n",
      "[SGD+StepLR] Epoch [3/10], Step [100/391], Loss: 1.5962, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [3/10], Step [200/391], Loss: 1.4716, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [3/10], Step [300/391], Loss: 1.4392, LR: 0.010000\n",
      "[SGD+StepLR] Epoch [3/10] Finished. Loss: 1.4828, Acc: 45.94%, LR: 0.001000\n",
      "\n",
      "[SGD+StepLR] Epoch [4/10], Step [100/391], Loss: 1.3020, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [4/10], Step [200/391], Loss: 1.1696, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [4/10], Step [300/391], Loss: 1.3307, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [4/10] Finished. Loss: 1.3145, Acc: 52.47%, LR: 0.001000\n",
      "\n",
      "[SGD+StepLR] Epoch [5/10], Step [100/391], Loss: 1.3451, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [5/10], Step [200/391], Loss: 1.2188, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [5/10], Step [300/391], Loss: 1.2820, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [5/10] Finished. Loss: 1.2691, Acc: 53.97%, LR: 0.001000\n",
      "\n",
      "[SGD+StepLR] Epoch [6/10], Step [100/391], Loss: 1.3534, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [6/10], Step [200/391], Loss: 1.3254, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [6/10], Step [300/391], Loss: 1.1395, LR: 0.001000\n",
      "[SGD+StepLR] Epoch [6/10] Finished. Loss: 1.2372, Acc: 55.23%, LR: 0.000100\n",
      "\n",
      "[SGD+StepLR] Epoch [7/10], Step [100/391], Loss: 1.1989, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [7/10], Step [200/391], Loss: 1.2232, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [7/10], Step [300/391], Loss: 1.0470, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [7/10] Finished. Loss: 1.2138, Acc: 56.03%, LR: 0.000100\n",
      "\n",
      "[SGD+StepLR] Epoch [8/10], Step [100/391], Loss: 1.2071, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [8/10], Step [200/391], Loss: 1.1413, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [8/10], Step [300/391], Loss: 1.4207, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [8/10] Finished. Loss: 1.2037, Acc: 56.45%, LR: 0.000100\n",
      "\n",
      "[SGD+StepLR] Epoch [9/10], Step [100/391], Loss: 1.2309, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [9/10], Step [200/391], Loss: 1.2126, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [9/10], Step [300/391], Loss: 1.3347, LR: 0.000100\n",
      "[SGD+StepLR] Epoch [9/10] Finished. Loss: 1.2017, Acc: 56.58%, LR: 0.000010\n",
      "\n",
      "[SGD+StepLR] Epoch [10/10], Step [100/391], Loss: 1.0530, LR: 0.000010\n",
      "[SGD+StepLR] Epoch [10/10], Step [200/391], Loss: 1.1463, LR: 0.000010\n",
      "[SGD+StepLR] Epoch [10/10], Step [300/391], Loss: 1.2625, LR: 0.000010\n",
      "[SGD+StepLR] Epoch [10/10] Finished. Loss: 1.1974, Acc: 56.70%, LR: 0.000010\n",
      "\n",
      "============================================================\n",
      "训练 Adam + CosineAnnealingLR 模型\n",
      "============================================================\n",
      "[Adam+Cosine] Epoch [1/10], Step [100/391], Loss: 1.7672, LR: 0.001000\n",
      "[Adam+Cosine] Epoch [1/10], Step [200/391], Loss: 1.7442, LR: 0.001000\n",
      "[Adam+Cosine] Epoch [1/10], Step [300/391], Loss: 1.5473, LR: 0.001000\n",
      "[Adam+Cosine] Epoch [1/10] Finished. Loss: 1.7915, Acc: 35.42%, LR: 0.000976\n",
      "\n",
      "[Adam+Cosine] Epoch [2/10], Step [100/391], Loss: 1.3964, LR: 0.000976\n",
      "[Adam+Cosine] Epoch [2/10], Step [200/391], Loss: 1.3819, LR: 0.000976\n",
      "[Adam+Cosine] Epoch [2/10], Step [300/391], Loss: 1.2154, LR: 0.000976\n",
      "[Adam+Cosine] Epoch [2/10] Finished. Loss: 1.3434, Acc: 51.21%, LR: 0.000905\n",
      "\n",
      "[Adam+Cosine] Epoch [3/10], Step [100/391], Loss: 1.1760, LR: 0.000905\n",
      "[Adam+Cosine] Epoch [3/10], Step [200/391], Loss: 1.2932, LR: 0.000905\n",
      "[Adam+Cosine] Epoch [3/10], Step [300/391], Loss: 1.1173, LR: 0.000905\n",
      "[Adam+Cosine] Epoch [3/10] Finished. Loss: 1.1049, Acc: 60.59%, LR: 0.000794\n",
      "\n",
      "[Adam+Cosine] Epoch [4/10], Step [100/391], Loss: 1.0127, LR: 0.000794\n",
      "[Adam+Cosine] Epoch [4/10], Step [200/391], Loss: 0.9208, LR: 0.000794\n",
      "[Adam+Cosine] Epoch [4/10], Step [300/391], Loss: 0.8903, LR: 0.000794\n",
      "[Adam+Cosine] Epoch [4/10] Finished. Loss: 0.9269, Acc: 67.40%, LR: 0.000655\n",
      "\n",
      "[Adam+Cosine] Epoch [5/10], Step [100/391], Loss: 0.7125, LR: 0.000655\n",
      "[Adam+Cosine] Epoch [5/10], Step [200/391], Loss: 0.8023, LR: 0.000655\n",
      "[Adam+Cosine] Epoch [5/10], Step [300/391], Loss: 0.8313, LR: 0.000655\n",
      "[Adam+Cosine] Epoch [5/10] Finished. Loss: 0.7894, Acc: 72.35%, LR: 0.000500\n",
      "\n",
      "[Adam+Cosine] Epoch [6/10], Step [100/391], Loss: 0.5981, LR: 0.000500\n",
      "[Adam+Cosine] Epoch [6/10], Step [200/391], Loss: 0.6329, LR: 0.000500\n"
     ]
    }
   ],
   "source": [
    "# ========== 导入库 ==========\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from src import ResNet74_ForwardDownsample, train_model, test_model\n",
    "\n",
    "# ========== 超参数 ==========\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 0.01  # 初始学习率（SGD通常需要更大的学习率）\n",
    "momentum = 0.9  # SGD的动量参数\n",
    "weight_decay = 1e-4  # 权重衰减（L2正则化）\n",
    "\n",
    "# ========== 数据加载 ==========\n",
    "# CIFAR-10 stats for normalization\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*stats),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 Dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ========== 模型定义 ==========\n",
    "# 创建模型\n",
    "model_sgd = ResNet74_ForwardDownsample(dropout_rate=0.0)\n",
    "model_adam = ResNet74_ForwardDownsample(dropout_rate=0.0)\n",
    "model_rmsprop = ResNet74_ForwardDownsample(dropout_rate=0.0)\n",
    "\n",
    "# 设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== 不同优化器配置 ==========\n",
    "# 1. SGD优化器 + StepLR学习率调度（阶梯式衰减）\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler_sgd = optim.lr_scheduler.StepLR(optimizer_sgd, step_size=3, gamma=0.1)  # 每3个epoch学习率乘以0.1\n",
    "\n",
    "# 2. Adam优化器 + CosineAnnealingLR学习率调度（余弦退火）\n",
    "optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "scheduler_adam = optim.lr_scheduler.CosineAnnealingLR(optimizer_adam, T_max=num_epochs)  # 余弦退火调度\n",
    "\n",
    "# 3. RMSprop优化器 + ExponentialLR学习率调度（指数衰减）\n",
    "optimizer_rmsprop = optim.RMSprop(model_rmsprop.parameters(), lr=0.001, weight_decay=weight_decay)\n",
    "scheduler_rmsprop = optim.lr_scheduler.ExponentialLR(optimizer_rmsprop, gamma=0.95)  # 每个epoch学习率乘以0.95\n",
    "\n",
    "# 将模型移动到GPU\n",
    "model_sgd.to(device)\n",
    "model_adam.to(device)\n",
    "model_rmsprop.to(device)\n",
    "\n",
    "# ========== 训练函数（带学习率调度） ==========\n",
    "def train_with_scheduler(model, trainloader, criterion, optimizer, scheduler, num_epochs, device, model_name):\n",
    "    \"\"\"训练模型，并在每个epoch后更新学习率\"\"\"\n",
    "    model.train()\n",
    "    total_step = len(trainloader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                print(f'[{model_name}] Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}, LR: {current_lr:.6f}')\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        epoch_acc = 100 * correct / total\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'[{model_name}] Epoch [{epoch+1}/{num_epochs}] Finished. Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%, LR: {current_lr:.6f}\\n')\n",
    "\n",
    "# ========== 训练不同优化器的模型 ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"训练 SGD + StepLR 模型\")\n",
    "print(\"=\" * 60)\n",
    "train_with_scheduler(model_sgd, trainloader, criterion, optimizer_sgd, scheduler_sgd, num_epochs, device, \"SGD+StepLR\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"训练 Adam + CosineAnnealingLR 模型\")\n",
    "print(\"=\" * 60)\n",
    "train_with_scheduler(model_adam, trainloader, criterion, optimizer_adam, scheduler_adam, num_epochs, device, \"Adam+Cosine\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"训练 RMSprop + ExponentialLR 模型\")\n",
    "print(\"=\" * 60)\n",
    "train_with_scheduler(model_rmsprop, trainloader, criterion, optimizer_rmsprop, scheduler_rmsprop, num_epochs, device, \"RMSprop+Exp\")\n",
    "\n",
    "# ========== 测试和比较 ==========\n",
    "print(\"=\" * 60)\n",
    "print(\"测试结果对比\")\n",
    "print(\"=\" * 60)\n",
    "test_acc_sgd = test_model(model_sgd, testloader, device)\n",
    "test_acc_adam = test_model(model_adam, testloader, device)\n",
    "test_acc_rmsprop = test_model(model_rmsprop, testloader, device)\n",
    "\n",
    "print(f\"SGD + StepLR 测试准确率: {test_acc_sgd:.2f}%\")\n",
    "print(f\"Adam + CosineAnnealingLR 测试准确率: {test_acc_adam:.2f}%\")\n",
    "print(f\"RMSprop + ExponentialLR 测试准确率: {test_acc_rmsprop:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
